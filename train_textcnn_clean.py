import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from torchtext.vocab import build_vocab_from_iterator
from torch.utils.data import DataLoader, Dataset
import jieba

print("ğŸ” [é˜¶æ®µ1] æ­£åœ¨åŠ è½½æ•°æ®...")
df = pd.read_csv("æƒ…æ„Ÿè¯„è®ºæ•°æ®é›†_sample.csv", encoding="utf-8-sig")
df["tokens"] = df["content"].apply(lambda x: [w for w in jieba.cut(x) if w.strip()])

# æ„å»ºè¯æ±‡è¡¨
def yield_tokens(data_iter):
    for tokens in data_iter:
        yield tokens

print("ğŸ” [é˜¶æ®µ2] æ„å»ºè¯è¡¨...")
vocab = build_vocab_from_iterator(yield_tokens(df["tokens"]), specials=["<pad>", "<unk>"])
vocab.set_default_index(vocab["<unk>"])

MAX_LEN = 30
def encode(tokens):
    ids = vocab(tokens)
    if len(ids) < MAX_LEN:
        ids += [vocab["<pad>"]] * (MAX_LEN - len(ids))
    else:
        ids = ids[:MAX_LEN]
    return ids

df["input_ids"] = df["tokens"].apply(encode)

# æ„å»º Dataset
class TextDataset(torch.utils.data.Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y
    def __len__(self):
        return len(self.X)
    def __getitem__(self, idx):
        return torch.tensor(self.X[idx]), torch.tensor(self.y[idx])

print("ğŸ” [é˜¶æ®µ3] åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†...")
X_train, X_test, y_train, y_test = train_test_split(df["input_ids"].tolist(), df["label"].tolist(), test_size=0.2, random_state=42)
train_dataset = TextDataset(X_train, y_train)
test_dataset = TextDataset(X_test, y_test)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8)

print(f"âœ… è®­ç»ƒæ ·æœ¬æ•°: {len(train_dataset)}, æµ‹è¯•æ ·æœ¬æ•°: {len(test_dataset)}")

class TextCNN(nn.Module):
    def __init__(self, vocab_size, embed_dim, num_classes):
        super(TextCNN, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)
        self.conv1 = nn.Conv2d(1, 100, (3, embed_dim))
        self.conv2 = nn.Conv2d(1, 100, (4, embed_dim))
        self.conv3 = nn.Conv2d(1, 100, (5, embed_dim))
        self.dropout = nn.Dropout(0.5)
        self.fc = nn.Linear(3 * 100, num_classes)

    def forward(self, x):
        x = self.embedding(x).unsqueeze(1)
        x1 = torch.relu(self.conv1(x)).squeeze(3)
        x1 = torch.max_pool1d(x1, x1.size(2)).squeeze(2)
        x2 = torch.relu(self.conv2(x)).squeeze(3)
        x2 = torch.max_pool1d(x2, x2.size(2)).squeeze(2)
        x3 = torch.relu(self.conv3(x)).squeeze(3)
        x3 = torch.max_pool1d(x3, x3.size(2)).squeeze(2)
        x = torch.cat((x1, x2, x3), dim=1)
        x = self.dropout(x)
        return self.fc(x)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = TextCNN(len(vocab), 100, 3).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)

print("ğŸš€ [é˜¶æ®µ4] å¼€å§‹è®­ç»ƒæ¨¡å‹...")
for epoch in range(10):
    model.train()
    total_loss = 0
    for X, y in train_loader:
        X, y = X.to(device), y.to(device)
        optimizer.zero_grad()
        out = model(X)
        loss = criterion(out, y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch+1}, Loss: {total_loss:.4f}")
print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

print("ğŸ§ª [é˜¶æ®µ5] å¼€å§‹æµ‹è¯•æ¨¡å‹...")
model.eval()
all_preds, all_labels = [], []
with torch.no_grad():
    for X, y in test_loader:
        X = X.to(device)
        out = model(X)
        preds = torch.argmax(out, dim=1).cpu().tolist()
        all_preds.extend(preds)
        all_labels.extend(y.tolist())

print("ğŸ“Š åˆ†ç±»æŠ¥å‘Šï¼š")
print(classification_report(all_labels, all_preds, target_names=["class0", "class1", "class2"]))

print("ğŸ“ˆ æ­£åœ¨ç”Ÿæˆæ··æ·†çŸ©é˜µå›¾...")
cm = confusion_matrix(all_labels, all_preds)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["0", "1", "2"],
            yticklabels=["0", "1", "2"],
            cbar=False)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("TextCNN Confusion Matrix")
plt.tight_layout()
plt.savefig("textcnn_confusion_matrix.png")
plt.show()
